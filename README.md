
<!-- README.md is generated from README.Rmd. Please edit that file -->

# hw3zyx

<!-- badges: start -->
<!-- badges: end -->

The goal of hw3zyx is to construct and compute linear models.

## Example

This is a basic example which shows you how to solve a common problem:

``` r
library(hw3zyx)
library(Rcpp)
## basic example code
```

## Instruction

<br/> Linear regression is a statistical model that analyzes the
relationship between variables. <br/> Compute the estimated coefficients
and statistics from linear models. <br/> Make the conclusion from the
result of the function whether there is a significant association
between the response and the variables. <br/>

Rcpp function <br/> Compute the covariance between y and x.

## Mathmetical Formula

$\hat{\beta}=(X^TX)^{-1}X^TY$ <br/> $\hat{Y}=\hat{\beta}X$ <br/>
$\hat{\epsilon}=Y-\hat{Y}$ <br/> $H=X(X^TX)^{-1}X^T$ <br/>
$SSY=Y^T(I_n-1/n)Y$ <br/> $SSR=Y^T(H-1/n)Y$ <br/> $SSE=Y^T(I_n-H)Y$
<br/> $MSR=SSR/(p-1)$ <br/> $MSE=SSE/(n-p)$ <br/>
$\hat{\sigma^2}=\frac{\hat{\epsilon}^T\hat{\epsilon}}{n-p}$ <br/>
$R^2=\frac{SSR}{SSY}$ <br/>
$R^2_{adjusted}=1-\frac{SSE/(n-p)}{SSY/(n-1)}$ <br/>
$Var(\hat{\beta})=X^TX\hat{\sigma^2}$ <br/>
$SE(\hat{\beta})=\sqrt{Var(\hat{\beta})}$ <br/>
$F=\frac{MSR}{\hat{\sigma^2}}$ <br/>
$t=\frac{\hat{\beta}}{SE(\hat{\beta})}$ <br/>
$cov(Y,X)=\frac{1}{n-1}\Sigma{(Y_i-\bar{Y})(X_i-\bar{X})}$

## Installation

You can install the development version of hw3zyx from
[GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("zyixuanUM/hw3")
```

## Test Cases

<br/> 1.

``` r
X <- c(151, 174, 138, 186, 128, 136, 179, 163, 152, 131)
Y <- c(63, 81, 56, 91, 47, 57, 76, 72, 62, 48)
data <- data.frame(Y,X)
linear_model(Y~X, data)
#> $`Summary of the coefficents`
#>             Estimate Std_Err  t_stat p_value
#> (Intercept) -38.4551  8.0490 -4.7776  0.0014
#> X             0.6746  0.0519 12.9970  0.0000
#> 
#> $`F test: F statistics and p value`
#>      [,1]       [,2]     
#> [1,] "168.9217" "< 0.001"
#> 
#> $`Residual standard error and R squared and adjusted R squared`
#>        [,1]   [,2]   [,3]
#> [1,] 3.2529 0.9548 0.9491
```

2.  

``` r
x <- cbind(mtcars$disp, mtcars$drat)
y <- mtcars$mpg
linear_model(y~x, mtcars)
#> $`Summary of the coefficents`
#>             Estimate Std_Err  t_stat p_value
#> (Intercept)  21.8449  6.7480  3.2373  0.0030
#> x1           -0.0357  0.0067 -5.3653  0.0000
#> x2            1.8020  1.5421  1.1686  0.2521
#> 
#> $`F test: F statistics and p value`
#>      [,1]      [,2]     
#> [1,] "39.4052" "< 0.001"
#> 
#> $`Residual standard error and R squared and adjusted R squared`
#>        [,1]  [,2]   [,3]
#> [1,] 3.2318 0.731 0.7125
```

<br/> \## Comparison <br/> Use all.equal() and expect_equal() in
testthat to compare the results between linear_model() and lm(). <br/>

## Reference

<br/> Linear regression model lm() function. <br/> Coviance cov()
function.

Youâ€™ll still need to render `README.Rmd` regularly, to keep `README.md`
up-to-date. `devtools::build_readme()` is handy for this. You could also
use GitHub Actions to re-render `README.Rmd` every time you push. An
example workflow can be found here:
<https://github.com/r-lib/actions/tree/v1/examples>.
